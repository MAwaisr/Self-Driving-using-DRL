{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682dd86f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'carla'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# FYP vehicle model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcarla\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mcarenv\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'carla'"
     ]
    }
   ],
   "source": [
    "# FYP vehicle model\n",
    "import carla\n",
    "class carenv:\n",
    "    def __init__(self):\n",
    "        self.imwidth\n",
    "        self.imhight\n",
    "        \n",
    "    def self():\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0d3a66b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SHOW_PREVIEW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCarEnv\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     SHOW_CAM \u001b[38;5;241m=\u001b[39m SHOW_PREVIEW\n\u001b[0;32m      3\u001b[0m     STEER_AMT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mCarEnv\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCarEnv\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     SHOW_CAM \u001b[38;5;241m=\u001b[39m SHOW_PREVIEW\n\u001b[0;32m      3\u001b[0m     STEER_AMT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m      5\u001b[0m     im_width \u001b[38;5;241m=\u001b[39m IMG_WIDTH\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SHOW_PREVIEW' is not defined"
     ]
    }
   ],
   "source": [
    "class CarEnv:\n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 1.0\n",
    "\n",
    "    im_width = IMG_WIDTH\n",
    "    im_height = IMG_HEIGHT\n",
    "    actor_list = []\n",
    "\n",
    "    front_camera = None\n",
    "    collision_hist = []\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = carla.Client('localhost', 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "\n",
    "        # Once we have a client we can retrieve the world that is currently\n",
    "        # running.\n",
    "        self.world = self.client.get_world()\n",
    "\n",
    "        # The world contains the list blueprints that we can use for adding new\n",
    "        # actors into the simulation.\n",
    "        blueprint_library = self.world.get_blueprint_library()\n",
    "\n",
    "        # Now let's filter all the blueprints of type 'vehicle' and choose one\n",
    "        # at random.\n",
    "        #print(blueprint_library.filter('vehicle'))\n",
    "        self.model_3 = blueprint_library.filter('model3')[0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "\n",
    "        self.transform = random.choice(self.world.get_map().get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.model_3, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "\n",
    "        self.rgb_cam = self.world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "\n",
    "        self.rgb_cam.set_attribute('image_size_x', f'{self.im_width}')\n",
    "        self.rgb_cam.set_attribute('image_size_y', f'{self.im_height}')\n",
    "        self.rgb_cam.set_attribute('fov', '110')\n",
    "\n",
    "\n",
    "        transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "\n",
    "        self.sensor = self.world.spawn_actor(self.rgb_cam, transform, attach_to=self.vehicle)\n",
    "\n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_img(data))\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "\n",
    "        time.sleep(4) # sleep to get things started and to not detect a collision when the car spawns/falls from sky.\n",
    "\n",
    "        colsensor = self.world.get_blueprint_library().find('sensor.other.collision')\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "\n",
    "        while self.front_camera is None:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        self.episode_start = time.time()\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(brake=0.0, throttle=0.0))\n",
    "\n",
    "        return self.front_camera\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarEnv:\n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 1.0\n",
    "    im_width = IM_WIDTH\n",
    "    im_height = IM_HEIGHT\n",
    "    front_camera = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = carla.Client(\"localhost\", 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "        self.world = self.client.get_world()\n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        self.model_3 = self.blueprint_library.filter(\"model3\")[0]\n",
    "        #/////////////////////////////////////////////////////////////////////////////////////\n",
    "        \n",
    "        #/////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "\n",
    "        self.transform = random.choice(self.world.get_map().get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.model_3, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "\n",
    "        self.rgb_cam = self.blueprint_library.find('sensor.camera.rgb')\n",
    "        self.rgb_cam.set_attribute(\"image_size_x\", f\"{self.im_width}\")\n",
    "        self.rgb_cam.set_attribute(\"image_size_y\", f\"{self.im_height}\")\n",
    "        self.rgb_cam.set_attribute(\"fov\", f\"110\")\n",
    "\n",
    "        transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        self.sensor = self.world.spawn_actor(self.rgb_cam, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_img(data))\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "        time.sleep(4)\n",
    "\n",
    "        colsensor = self.blueprint_library.find(\"sensor.other.collision\")\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "\n",
    "        while self.front_camera is None:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        self.episode_start = time.time()\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "\n",
    "        return self.front_camera\n",
    "\n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "\n",
    "    def process_img(self, image):\n",
    "        i = np.array(image.raw_data)\n",
    "        #print(i.shape)\n",
    "        i2 = i.reshape((self.im_height, self.im_width, 4))\n",
    "        i3 = i2[:, :, :3]\n",
    "        if self.SHOW_CAM:\n",
    "            cv2.imshow(\"\", i3)\n",
    "            cv2.waitKey(1)\n",
    "        self.front_camera = i3\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1*self.STEER_AMT)) # moves to left\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer= 0))\n",
    "        elif action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=1*self.STEER_AMT)) # moves to right\n",
    "\n",
    "        v = self.vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "\n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True # this is telling that while training, if collision occurs, then we are done, so that model trains in a way not to make a collision \n",
    "            reward = -200\n",
    "        elif kmh < 50:\n",
    "            done = False\n",
    "            reward = -1 # this is basically to train the model so that it will not remain below 50km/h but try to enchance the speed instead\n",
    "        #furthur rewards should be added which may take more time but will surely enhance the model\n",
    "        # separate the reward for collision with pedestrain and vehicle or some static object\n",
    "        # reward for traffic lights, crossing lanes, crossing footpaths, taking a sudden break\n",
    "        # order of reward from highest to lowest should go like this\n",
    "        '''\n",
    "        collision with pedestrain\n",
    "        collision with vehicle\n",
    "        collision with static object\n",
    "        crossing traffic signals, crossing lines, crossing footpaths\n",
    "        taking a sudden break\n",
    "        \n",
    "        '''\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 1\n",
    "\n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "\n",
    "        return self.front_camera, reward, done, None # self.front_camera will be the new state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab774ae0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+007F (140458897.py, line 160)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 160\u001b[1;36m\u001b[0m\n\u001b[1;33m    base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH,3))\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+007F\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from collections import deque\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla\n",
    "\n",
    "\n",
    "SHOW_PREVIEW = False\n",
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "SECONDS_PER_EPISODE = 10\n",
    "REPLAY_MEMORY_SIZE = 5_000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 16\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = MINIBATCH_SIZE // 4\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "MEMORY_FRACTION = 0.8\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 100\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.95 ## 0.9975 99975\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "AGGREGATE_STATS_EVERY = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "\n",
    "        self.tensorboard = ModifiedTensorBoard(log_dir=f\"logs/{MODEL_NAME}-{int(time.time())}\")\n",
    "        self.target_update_counter = 0\n",
    "        self.graph = tf.get_default_graph()\n",
    "\n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "\n",
    "    def create_model(self):\n",
    "        base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH,3))\n",
    "\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        predictions = Dense(3, activation=\"linear\")(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001), metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    def update_replay_memory(self, transition):\n",
    "        # transition = (current_state, action, reward, new_state, done)\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "\n",
    "        current_states = np.array([transition[0] for transition in minibatch])/255\n",
    "        with self.graph.as_default():\n",
    "            current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])/255\n",
    "        with self.graph.as_default():\n",
    "            future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "\n",
    "        log_this_step = False\n",
    "        if self.tensorboard.step > self.last_logged_episode:\n",
    "            log_this_step = True\n",
    "            self.last_log_episode = self.tensorboard.step\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(np.array(X)/255, np.array(y), batch_size=TRAINING_BATCH_SIZE, verbose=0, shuffle=False, callbacks=[self.tensorboard] if log_this_step else None)\n",
    "\n",
    "\n",
    "        if log_this_step:\n",
    "            self.target_update_counter += 1\n",
    "\n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1, *state.shape)/255)[0]\n",
    "\n",
    "    def train_in_loop(self):\n",
    "        X = np.random.uniform(size=(1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "        y = np.random.uniform(size=(1, 3)).astype(np.float32)\n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(X,y, verbose=False, batch_size=1)\n",
    "\n",
    "        self.training_initialized = True\n",
    "\n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                return\n",
    "            self.train()\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f662283b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open-interpreter\n",
      "  Obtaining dependency information for open-interpreter from https://files.pythonhosted.org/packages/54/4e/d4a755f65f3da7164d8a1a051d6073407d77bf9b3d8d42c244e80d4aa69d/open_interpreter-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading open_interpreter-0.1.3-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from open-interpreter) (1.4.4)\n",
      "Collecting astor<0.9.0,>=0.8.1 (from open-interpreter)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting git-python<2.0.0,>=1.0.3 (from open-interpreter)\n",
      "  Downloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting huggingface-hub<0.17.0,>=0.16.4 (from open-interpreter)\n",
      "  Obtaining dependency information for huggingface-hub<0.17.0,>=0.16.4 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting inquirer<4.0.0,>=3.1.3 (from open-interpreter)\n",
      "  Downloading inquirer-3.1.3-py3-none-any.whl (18 kB)\n",
      "Collecting litellm<0.2.0,>=0.1.578 (from open-interpreter)\n",
      "  Obtaining dependency information for litellm<0.2.0,>=0.1.578 from https://files.pythonhosted.org/packages/b5/da/f1814e6c66bb7c8b3ed0eb4142e7f5ee2f411738be5b87fd3f360f346f52/litellm-0.1.609-py3-none-any.whl.metadata\n",
      "  Downloading litellm-0.1.609-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting openai<0.28.0,>=0.27.8 (from open-interpreter)\n",
      "  Obtaining dependency information for openai<0.28.0,>=0.27.8 from https://files.pythonhosted.org/packages/f1/1f/3a0cb7d172f451b2ca8bf65d9196aa3b6878c010d461257c621e4bd48cad/openai-0.27.10-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.27.10-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyreadline3<4.0.0,>=3.4.1 (from open-interpreter)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "     ---------------------------------------- 0.0/95.2 kB ? eta -:--:--\n",
      "     ----------------- ---------------------- 41.0/95.2 kB ? eta -:--:--\n",
      "     ----------------- ---------------------- 41.0/95.2 kB ? eta -:--:--\n",
      "     ----------------- ---------------------- 41.0/95.2 kB ? eta -:--:--\n",
      "     ------------------------ ------------- 61.4/95.2 kB 326.1 kB/s eta 0:00:01\n",
      "     ------------------------ ------------- 61.4/95.2 kB 326.1 kB/s eta 0:00:01\n",
      "     -------------------------------------- 95.2/95.2 kB 319.4 kB/s eta 0:00:00\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from open-interpreter)\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting rich<14.0.0,>=13.4.2 (from open-interpreter)\n",
      "  Obtaining dependency information for rich<14.0.0,>=13.4.2 from https://files.pythonhosted.org/packages/8d/5f/21a93b2ec205f4b79853ff6e838e3c99064d5dbe85ec6b05967506f14af0/rich-13.5.2-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.5.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six<2.0.0,>=1.16.0 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from open-interpreter) (1.16.0)\n",
      "Collecting tiktoken<0.5.0,>=0.4.0 (from open-interpreter)\n",
      "  Downloading tiktoken-0.4.0-cp311-cp311-win_amd64.whl (635 kB)\n",
      "     ---------------------------------------- 0.0/635.3 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 41.0/635.3 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 71.7/635.3 kB 975.2 kB/s eta 0:00:01\n",
      "     ---- -------------------------------- 71.7/635.3 kB 975.2 kB/s eta 0:00:01\n",
      "     ----- ------------------------------- 92.2/635.3 kB 525.1 kB/s eta 0:00:02\n",
      "     ------ ----------------------------- 112.6/635.3 kB 544.7 kB/s eta 0:00:01\n",
      "     -------- --------------------------- 153.6/635.3 kB 538.9 kB/s eta 0:00:01\n",
      "     ----------- ------------------------ 194.6/635.3 kB 588.9 kB/s eta 0:00:01\n",
      "     ----------- ------------------------ 194.6/635.3 kB 588.9 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 225.3/635.3 kB 550.0 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 225.3/635.3 kB 550.0 kB/s eta 0:00:01\n",
      "     ---------------- ------------------- 286.7/635.3 kB 589.5 kB/s eta 0:00:01\n",
      "     ---------------- ------------------- 286.7/635.3 kB 589.5 kB/s eta 0:00:01\n",
      "     -------------------- --------------- 358.4/635.3 kB 602.4 kB/s eta 0:00:01\n",
      "     -------------------- --------------- 358.4/635.3 kB 602.4 kB/s eta 0:00:01\n",
      "     -------------------- --------------- 358.4/635.3 kB 602.4 kB/s eta 0:00:01\n",
      "     ---------------------- ------------- 389.1/635.3 kB 527.0 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 409.6/635.3 kB 532.5 kB/s eta 0:00:01\n",
      "     ------------------------ ----------- 430.1/635.3 kB 537.6 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 450.6/635.3 kB 512.0 kB/s eta 0:00:01\n",
      "     --------------------------- -------- 481.3/635.3 kB 519.9 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 512.0/635.3 kB 526.5 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 512.0/635.3 kB 526.5 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 532.5/635.3 kB 491.3 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 542.7/635.3 kB 293.7 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 542.7/635.3 kB 293.7 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 542.7/635.3 kB 293.7 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 542.7/635.3 kB 293.7 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 573.4/635.3 kB 286.0 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 573.4/635.3 kB 286.0 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 593.9/635.3 kB 280.9 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 593.9/635.3 kB 280.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 614.4/635.3 kB 280.2 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 614.4/635.3 kB 280.2 kB/s eta 0:00:01\n",
      "     -----------------------------------  624.6/635.3 kB 269.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 635.3/635.3 kB 272.1 kB/s eta 0:00:00\n",
      "Collecting tokentrim<0.2.0,>=0.1.9 (from open-interpreter)\n",
      "  Obtaining dependency information for tokentrim<0.2.0,>=0.1.9 from https://files.pythonhosted.org/packages/53/5a/8439751019c66081f96cce70c921a1d779d36fd15e7207c892a09e8b56f6/tokentrim-0.1.10-py3-none-any.whl.metadata\n",
      "  Downloading tokentrim-0.1.10-py3-none-any.whl.metadata (589 bytes)\n",
      "Collecting wget<4.0,>=3.2 (from open-interpreter)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gitpython (from git-python<2.0.0,>=1.0.3->open-interpreter)\n",
      "  Obtaining dependency information for gitpython from https://files.pythonhosted.org/packages/f9/94/1877b88fa3a0a30bedb43757a14f548c3b2719c8d83c16012f89564c0f3b/GitPython-3.1.36-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.36-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (3.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (2023.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (23.0)\n",
      "Collecting blessed>=1.19.0 (from inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
      "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.4 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/58.4 kB ? eta -:--:--\n",
      "     -------------------------- ----------- 41.0/58.4 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 41.0/58.4 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 41.0/58.4 kB 487.6 kB/s eta 0:00:01\n",
      "     --------------------------------- ---- 51.2/58.4 kB 200.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 58.4/58.4 kB 192.5 kB/s eta 0:00:00\n",
      "Collecting python-editor>=1.0.4 (from inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Collecting readchar>=3.0.6 (from inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
      "  Downloading readchar-4.0.5-py3-none-any.whl (8.5 kB)\n",
      "Collecting importlib-metadata<7.0.0,>=6.8.0 (from litellm<0.2.0,>=0.1.578->open-interpreter)\n",
      "  Obtaining dependency information for importlib-metadata<7.0.0,>=6.8.0 from https://files.pythonhosted.org/packages/cc/37/db7ba97e676af155f5fcb1a35466f446eadc9104e25b83366e8088c9c926/importlib_metadata-6.8.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_metadata-6.8.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\92300\\anaconda3\\lib\\site-packages (from openai<0.28.0,>=0.27.8->open-interpreter) (3.8.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.4.2->open-interpreter) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from rich<14.0.0,>=13.4.2->open-interpreter) (2.15.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from tiktoken<0.5.0,>=0.4.0->open-interpreter) (2022.7.9)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter) (0.2.5)\n",
      "Collecting jinxed>=1.1.0 (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
      "  Downloading jinxed-1.2.0-py2.py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from importlib-metadata<7.0.0,>=6.8.0->litellm<0.2.0,>=0.1.578->open-interpreter) (3.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.4.2->open-interpreter) (0.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from readchar>=3.0.6->inquirer<4.0.0,>=3.1.3->open-interpreter) (68.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\92300\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<0.17.0,>=0.16.4->open-interpreter) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.8->open-interpreter) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.8->open-interpreter) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.8->open-interpreter) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.8->open-interpreter) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.8->open-interpreter) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\92300\\anaconda3\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.8->open-interpreter) (1.2.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython->git-python<2.0.0,>=1.0.3->open-interpreter)\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->git-python<2.0.0,>=1.0.3->open-interpreter)\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting ansicon (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<4.0.0,>=3.1.3->open-interpreter)\n",
      "  Downloading ansicon-1.89.0-py2.py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 0.0/63.7 kB ? eta -:--:--\n",
      "     -------------------------------------- - 61.4/63.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 63.7/63.7 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading open_interpreter-0.1.3-py3-none-any.whl (32 kB)\n",
      "Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.8 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----- --------------------------------- 41.0/268.8 kB 991.0 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 153.6/268.8 kB 353.1 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 153.6/268.8 kB 353.1 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 153.6/268.8 kB 353.1 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 153.6/268.8 kB 353.1 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 174.1/268.8 kB 275.8 kB/s eta 0:00:01\n",
      "   ------------------------------- ------ 225.3/268.8 kB 344.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 235.5/268.8 kB 343.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 235.5/268.8 kB 343.4 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 235.5/268.8 kB 343.4 kB/s eta 0:00:01\n",
      "   -------------------------------------  266.2/268.8 kB 314.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 268.8/268.8 kB 300.7 kB/s eta 0:00:00\n",
      "Downloading litellm-0.1.609-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 41.0/115.3 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 41.0/115.3 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 41.0/115.3 kB ? eta -:--:--\n",
      "   -------------------------------------- 115.3/115.3 kB 558.7 kB/s eta 0:00:00\n",
      "Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/76.5 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 71.7/76.5 kB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.5/76.5 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "   ---------------------------------------- 0.0/239.7 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/239.7 kB 660.6 kB/s eta 0:00:01\n",
      "   ---- ---------------------------------- 30.7/239.7 kB 660.6 kB/s eta 0:00:01\n",
      "   ------------- ------------------------- 81.9/239.7 kB 573.4 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 92.2/239.7 kB 525.1 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 112.6/239.7 kB 149.1 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 112.6/239.7 kB 149.1 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/239.7 kB 144.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/239.7 kB 144.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/239.7 kB 144.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/239.7 kB 144.2 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 122.9/239.7 kB 144.2 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 194.6/239.7 kB 178.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 225.3/239.7 kB 199.5 kB/s eta 0:00:01\n",
      "   ----------------------------------- -- 225.3/239.7 kB 199.5 kB/s eta 0:00:01\n",
      "   -------------------------------------  235.5/239.7 kB 197.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 239.7/239.7 kB 193.3 kB/s eta 0:00:00\n",
      "Downloading tokentrim-0.1.10-py3-none-any.whl (4.1 kB)\n",
      "Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/189.5 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 41.0/189.5 kB 487.6 kB/s eta 0:00:01\n",
      "   -------------- ------------------------ 71.7/189.5 kB 558.5 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 112.6/189.5 kB 595.3 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 143.4/189.5 kB 652.5 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 174.1/189.5 kB 697.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 174.1/189.5 kB 697.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 174.1/189.5 kB 697.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 174.1/189.5 kB 697.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 174.1/189.5 kB 697.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 174.1/189.5 kB 697.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 184.3/189.5 kB 348.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- 189.5/189.5 kB 318.4 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=53a8e96c1871e9a0e9859ed36e6fbd4df3033f66aab93f5c580fc61614290f07\n",
      "  Stored in directory: c:\\users\\92300\\appdata\\local\\pip\\cache\\wheels\\40\\b3\\0f\\a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built wget\n",
      "Installing collected packages: wget, python-editor, pyreadline3, ansicon, smmap, readchar, python-dotenv, jinxed, importlib-metadata, astor, tiktoken, rich, huggingface-hub, gitdb, blessed, tokentrim, openai, inquirer, gitpython, litellm, git-python, open-interpreter\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed ansicon-1.89.0 astor-0.8.1 blessed-1.20.0 git-python-1.0.3 gitdb-4.0.10 gitpython-3.1.36 huggingface-hub-0.16.4 importlib-metadata-6.8.0 inquirer-3.1.3 jinxed-1.2.0 litellm-0.1.609 open-interpreter-0.1.3 openai-0.27.10 pyreadline3-3.4.1 python-dotenv-1.0.0 python-editor-1.0.4 readchar-4.0.5 rich-13.5.2 smmap-5.0.0 tiktoken-0.4.0 tokentrim-0.1.10 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install open-interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100b1f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'interpreter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m interpreter(hello)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'interpreter' is not defined"
     ]
    }
   ],
   "source": [
    "interpreter(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5ebe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\92300\\anaconda3\\Lib\\site-packages\\blessed\\terminal.py:183: UserWarning: Failed to setupterm(kind='xterm-color'): Could not find terminal xterm-color\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0bdc17d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+007F (2457190286.py, line 160)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 160\u001b[1;36m\u001b[0m\n\u001b[1;33m    base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH,3))\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+007F\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from collections import deque\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "try:\n",
    "    sys.path.append(glob.glob('../carla/dist/carla-*%d.%d-%s.egg' % (\n",
    "        sys.version_info.major,\n",
    "        sys.version_info.minor,\n",
    "        'win-amd64' if os.name == 'nt' else 'linux-x86_64'))[0])\n",
    "except IndexError:\n",
    "    pass\n",
    "import carla\n",
    "\n",
    "\n",
    "SHOW_PREVIEW = False\n",
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 480\n",
    "SECONDS_PER_EPISODE = 10\n",
    "REPLAY_MEMORY_SIZE = 5_000\n",
    "MIN_REPLAY_MEMORY_SIZE = 1_000\n",
    "MINIBATCH_SIZE = 16\n",
    "PREDICTION_BATCH_SIZE = 1\n",
    "TRAINING_BATCH_SIZE = MINIBATCH_SIZE // 4\n",
    "UPDATE_TARGET_EVERY = 5\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "MEMORY_FRACTION = 0.8\n",
    "MIN_REWARD = -200\n",
    "\n",
    "EPISODES = 100\n",
    "\n",
    "DISCOUNT = 0.99\n",
    "epsilon = 1\n",
    "EPSILON_DECAY = 0.95 ## 0.9975 99975\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "AGGREGATE_STATS_EVERY = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CarEnv:\n",
    "    SHOW_CAM = SHOW_PREVIEW\n",
    "    STEER_AMT = 1.0\n",
    "    im_width = IM_WIDTH\n",
    "    im_height = IM_HEIGHT\n",
    "    front_camera = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = carla.Client(\"localhost\", 2000)\n",
    "        self.client.set_timeout(2.0)\n",
    "        self.world = self.client.get_world()\n",
    "        self.blueprint_library = self.world.get_blueprint_library()\n",
    "        self.model_3 = self.blueprint_library.filter(\"model3\")[0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.collision_hist = []\n",
    "        self.actor_list = []\n",
    "\n",
    "        self.transform = random.choice(self.world.get_map().get_spawn_points())\n",
    "        self.vehicle = self.world.spawn_actor(self.model_3, self.transform)\n",
    "        self.actor_list.append(self.vehicle)\n",
    "\n",
    "        self.rgb_cam = self.blueprint_library.find('sensor.camera.rgb')\n",
    "        self.rgb.set_attribute(\"image_size_x\", f\"{self.im_width}\")\n",
    "        self.rgb.set_attribute(\"image_size_y\", f\"{self.im_height}\")\n",
    "        self.rgb.set_attribute(\"fov\", f\"110\")\n",
    "\n",
    "        transform = carla.Transform(carla.Location(x=2.5, z=0.7))\n",
    "        self.sensor = self.world.spawn_actor(self.rgb_cam, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.sensor)\n",
    "        self.sensor.listen(lambda data: self.process_img(data))\n",
    "\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "        time.sleep(4)\n",
    "\n",
    "        colsensor = self.blueprint_library.find(\"sensor.other.collision\")\n",
    "        self.colsensor = self.world.spawn_actor(colsensor, transform, attach_to=self.vehicle)\n",
    "        self.actor_list.append(self.colsensor)\n",
    "        self.colsensor.listen(lambda event: self.collision_data(event))\n",
    "\n",
    "        while self.front_camera is None:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "        self.episode_start = time.time()\n",
    "        self.vehicle.apply_control(carla.VehicleControl(throttle=0.0, brake=0.0))\n",
    "\n",
    "        return self.front_camera\n",
    "\n",
    "    def collision_data(self, event):\n",
    "        self.collision_hist.append(event)\n",
    "\n",
    "    def process_img(self, image):\n",
    "        i = np.array(image.raw_data)\n",
    "        #print(i.shape)\n",
    "        i2 = i.reshape((self.im_height, self.im_width, 4))\n",
    "        i3 = i2[:, :, :3]\n",
    "        if self.SHOW_CAM:\n",
    "            cv2.imshow(\"\", i3)\n",
    "            cv2.waitKey(1)\n",
    "        self.front_camera = i3\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=-1*self.STEER_AMT))\n",
    "        elif action == 1:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer= 0))\n",
    "        elif action == 2:\n",
    "            self.vehicle.apply_control(carla.VehicleControl(throttle=1.0, steer=1*self.STEER_AMT))\n",
    "\n",
    "        v = self.vehicle.get_velocity()\n",
    "        kmh = int(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2))\n",
    "\n",
    "        if len(self.collision_hist) != 0:\n",
    "            done = True\n",
    "            reward = -200\n",
    "        elif kmh < 50:\n",
    "            done = False\n",
    "            reward = -1\n",
    "        else:\n",
    "            done = False\n",
    "            reward = 1\n",
    "\n",
    "        if self.episode_start + SECONDS_PER_EPISODE < time.time():\n",
    "            done = True\n",
    "\n",
    "        return self.front_camera, reward, done, None\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        self.model = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        self.replay_memory = deque(maxlen=REPLAY_MEMORY_SIZE)\n",
    "\n",
    "        self.tensorboard = ModifiedTensorBoard(log_dir=f\"logs/{MODEL_NAME}-{int(time.time())}\")\n",
    "        self.target_update_counter = 0\n",
    "        self.graph = tf.get_default_graph()\n",
    "\n",
    "        self.terminate = False\n",
    "        self.last_logged_episode = 0\n",
    "        self.training_initialized = False\n",
    "\n",
    "    def create_model(self):\n",
    "        base_model = Xception(weights=None, include_top=False, input_shape=(IM_HEIGHT, IM_WIDTH,3))\n",
    "\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        predictions = Dense(3, activation=\"linear\")(x)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001), metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    def update_replay_memory(self, transition):\n",
    "        # transition = (current_state, action, reward, new_state, done)\n",
    "        self.replay_memory.append(transition)\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.replay_memory) < MIN_REPLAY_MEMORY_SIZE:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.replay_memory, MINIBATCH_SIZE)\n",
    "\n",
    "        current_states = np.array([transition[0] for transition in minibatch])/255\n",
    "        with self.graph.as_default():\n",
    "            current_qs_list = self.model.predict(current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])/255\n",
    "        with self.graph.as_default():\n",
    "            future_qs_list = self.target_model.predict(new_current_states, PREDICTION_BATCH_SIZE)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "\n",
    "        for index, (current_state, action, reward, new_state, done) in enumerate(minibatch):\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + DISCOUNT * max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "\n",
    "        log_this_step = False\n",
    "        if self.tensorboard.step > self.last_logged_episode:\n",
    "            log_this_step = True\n",
    "            self.last_log_episode = self.tensorboard.step\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(np.array(X)/255, np.array(y), batch_size=TRAINING_BATCH_SIZE, verbose=0, shuffle=False, callbacks=[self.tensorboard] if log_this_step else None)\n",
    "\n",
    "\n",
    "        if log_this_step:\n",
    "            self.target_update_counter += 1\n",
    "\n",
    "        if self.target_update_counter > UPDATE_TARGET_EVERY:\n",
    "            self.target_model.set_weights(self.model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "\n",
    "    def get_qs(self, state):\n",
    "        return self.model.predict(np.array(state).reshape(-1 *state.shape)/255)[0]\n",
    "\n",
    "    def train_in_loop(self):\n",
    "        X = np.random.uniform(size=(1, IM_HEIGHT, IM_WIDTH, 3)).astype(np.float32)\n",
    "        y = np.random.uniform(size=(1, 3)).astype(np.float32)\n",
    "        with self.graph.as_default():\n",
    "            self.model.fit(X,y, verbose=False, batch_size=1)\n",
    "\n",
    "        self.training_initialized = True\n",
    "\n",
    "        while True:\n",
    "            if self.terminate:\n",
    "                return\n",
    "            self.train()\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d450495",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Interpreter' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m interpreter()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Interpreter' object is not callable"
     ]
    }
   ],
   "source": [
    "interpreter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59144720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40548ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
